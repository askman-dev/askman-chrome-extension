# [provider]: A group identifier for model configurations
# The name here can be customized without affecting the actual API request
# For example, [chatglm] can be renamed to [gem] or [paid-openai]
# Just ensure it's unique within this config file
[siliconflow]
# The protocol used to send requests, currently only supporting openai, is HTTPS
sdk = "openai" 
# API key, left empty here
api_key = "sk-xxx" 
# Base URL for API requests
base_url = "https://extapi.askman.dev/v1/"
send_api_key = false
cloudflare_gateway_url = ""
models = [
  { name = "THUDM/glm-4-9b-chat", max_tokens = 32768 } # THUDM/glm-4-9b-chat via siliconflow
]
[openrouter]
api_key = "sk-xxx"
base_url = "https://extapi.askman.dev/v1/"
sdk = "openai"
send_api_key = true
models = [
  { max_tokens = 32786, name = "deepseek/deepseek-r1:free" },
  { max_tokens = 32786, name = "qwen/qwq-32b:free" },
  { max_tokens = 32786, name = "google/gemma-3-27b-it:free" }
]

# [openai]
# sdk = "openai"  # Protocol used to send requests
# api_key = "sk-xxx" # Your OpenAI API key
# base_url = "https://api.openai.com/v1" # Concatenation logic is {base_url}/chat/completions
# send_api_key = true # Whether to include the API Key in headers
# cloudflare_gateway_url = "" # Use Cloudflare Gateway proxy
# models = [
#   { name = "gpt-3.5-turbo", max_tokens = 4096 },
#   { name = "gpt-4", max_tokens = 8192 }
# ]

# The following is not yet supported
# [azure]
# api_key = ""
# endpoint = ""
# models = [
#   { name = "gpt-3.5-turbo", max_tokens = 4096 },
#   { name = "gpt-4", max_tokens = 8192 }
# ]

# [anthropic]
# api_key = ""
# models = [
#   { name = "claude-2", max_tokens = 100000 },
#   { name = "claude-instant-1", max_tokens = 100000 }
# ]

# [google]
# api_key = ""
# models = [
#   { name = "gemini-pro", max_tokens = 30720 },
#   { name = "text-bison", max_tokens = 8192 }
# ]

# [groq]
# api_key = ""
# models = [
#   { name = "llama2-70b-4096", max_tokens = 4096 },
#   { name = "mixtral-8x7b-32768", max_tokens = 32768 }
# ]

# [ollama]
# api_base = "http://localhost:11434"
# models = [
#   { name = "llama2", max_tokens = 4096 },
#   { name = "mistral", max_tokens = 8192 }
# ]

# [openrouter]
# api_key = ""
# models = []
